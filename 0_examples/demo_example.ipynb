{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils.globals import PATH_TO_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Define transformations for the training and validation sets\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),            # Resize images to 224x224 for pretrained models\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),  # Normalize with MNIST mean and std\n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1))  # Convert 1-channel grayscale to 3-channel\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Download and load the training and test datasets\n",
    "# pass the root folder, as it will create the directory MNIST automatically\n",
    "train_dataset = datasets.MNIST(root=PATH_TO_ROOT, train=True, download=True, transform=transform)\n",
    "test_dataset  = datasets.MNIST(root=PATH_TO_ROOT, train=False, download=True, transform=transform)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Define training and validation indices\n",
    "validation_split = 0.1\n",
    "shuffle_dataset = True\n",
    "random_seed = 42\n",
    "\n",
    "dataset_size = len(train_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Create data samplers and loaders\n",
    "batch_size = 128\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "validation_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lorenzo\\anaconda3\\envs\\cudaenv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lorenzo\\anaconda3\\envs\\cudaenv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load a non-pretrained ResNet18 model\n",
    "model = models.resnet18(pretrained=False)\n",
    "\n",
    "# Modify the final layer to match the number of classes in MNIST\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 10)  # MNIST has 10 classes (digits 0-9)\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3]\n",
      "Current Learning Rate: 0.001000\n",
      "Train Loss: 0.1225, Train Acc: 96.35% | Val Loss: 0.0735, Val Acc: 97.85%\n",
      "\n",
      "Epoch [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3]\n",
      "Current Learning Rate: 0.000100\n",
      "Train Loss: 0.0227, Train Acc: 99.31% | Val Loss: 0.0216, Val Acc: 99.40%\n",
      "\n",
      "Epoch [3/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:  53%|█████▎    | 25/47 [3:51:52<17:50:52, 2920.55s/it, Batch Loss=0.0082]              "
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "train_accuracies = []\n",
    "valid_accuracies = []\n",
    "best_val_acc = 0.0\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "    # Training\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Initialize the progress bar for training\n",
    "    train_progress_bar = tqdm(train_loader, desc='Training', leave=False)\n",
    "\n",
    "    for images, labels in train_progress_bar:\n",
    "        # Move data to device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Statistics\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Update progress bar with current loss and accuracy\n",
    "        batch_acc = 100 * (predicted == labels).sum().item() / labels.size(0)\n",
    "        train_progress_bar.set_postfix({'Batch Loss': loss.item(), 'Batch Acc': f'{batch_acc:.2f}%'})\n",
    "\n",
    "    epoch_loss = running_loss / len(train_indices)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_acc)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Initialize the progress bar for validation\n",
    "    val_progress_bar = tqdm(validation_loader, desc='Validation', leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_progress_bar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update progress bar with current loss\n",
    "            val_progress_bar.set_postfix({'Batch Loss': loss.item()})\n",
    "\n",
    "    val_loss = val_loss / len(val_indices)\n",
    "    val_acc = 100 * correct / total\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "    valid_losses.append(val_loss)\n",
    "    valid_accuracies.append(val_acc)\n",
    "\n",
    "    # Print epoch statistics\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}]')\n",
    "    print(f'Current Learning Rate: {scheduler.get_last_lr()[0]:.6f}')\n",
    "    print(f'Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.2f}% | '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\\n')\n",
    "\n",
    "    # Step the scheduler\n",
    "    scheduler.step()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Testing the model with progress bar\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Initialize the progress bar for testing\n",
    "test_progress_bar = tqdm(test_loader, desc='Testing', leave=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_progress_bar:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Update progress bar with current accuracy\n",
    "        current_accuracy = 100 * correct / total\n",
    "        test_progress_bar.set_postfix({'Accuracy': f'{current_accuracy:.2f}%'})\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot loss curves\n",
    "plt.figure(figsize=(12, 5))\n",
    "x = range(1, num_epochs+1)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x, train_losses, label='Training Loss')\n",
    "plt.plot(x, valid_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs. Epoch')\n",
    "plt.legend()\n",
    "\n",
    "# Plot accuracy curves\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x, train_accuracies, label='Training Accuracy')\n",
    "plt.plot(x, valid_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy vs. Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
